---
# yamllint disable rule:truthy rule:line-length rule:comments
permissions:
  contents: read

name: Hybrid CI
concurrency:
  group: ci-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches: [main]
    paths:
      - .github/workflows/ci.yml
      - docker/**
      - scripts/**
      - .devcontainer/**
      - pixi.toml
      - pixi.lock
      - pyproject.toml
  schedule:
    - cron: "0 4 * * 1"
  workflow_dispatch:

jobs:
  lint:
    env:
      PIXI_PLATFORM: linux-64
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          persist-credentials: false
      - name: Set artifacts dir
        run: echo "ARTIFACTS_DIR=$RUNNER_TEMP/artifacts-lint" >> "$GITHUB_ENV"
      - name: Prepare artifacts directory
        run: mkdir -p "$ARTIFACTS_DIR"
      - uses: prefix-dev/setup-pixi@82d477f15f3a381dbcc8adc1206ce643fe110fb7 # v0.9.3
        with:
          cache: true
          locked: true
          environments: automation
      - name: Collect pixi metadata
        run: |
          mkdir -p "$ARTIFACTS_DIR/pixi"
          cp pixi.toml pixi.lock "$ARTIFACTS_DIR/pixi/"
          set +e
          pixi info --json > "$ARTIFACTS_DIR/pixi/info.json" || echo '{"note":"pixi info unavailable"}' > "$ARTIFACTS_DIR/pixi/info.json"
          pixi list --json > "$ARTIFACTS_DIR/pixi/list.json" || echo '{"note":"pixi list unavailable"}' > "$ARTIFACTS_DIR/pixi/list.json"
          pixi tree -e automation > "$ARTIFACTS_DIR/pixi/tree.txt" || echo "pixi tree unavailable" > "$ARTIFACTS_DIR/pixi/tree.txt"
          echo '{"note":"pixi manifest/diff/updates_github_actions CLI not available in pixi 0.62.2; captured manifest + lock instead."}' > "$ARTIFACTS_DIR/pixi/notes.json"
          set -e
      - name: Hadolint (Dockerfile)
        uses: hadolint/hadolint-action@2332a7b74a6de0dda2e2221d575162eba76ba5e5 # v3.3.0
        with:
          dockerfile: docker/Dockerfile
      - name: Run lint suite
        env:
          RUN_SEMGREP: "1"
        run: |
          set -o pipefail
          pixi run -e automation lint | tee "$ARTIFACTS_DIR/lint.log"
      - name: Ensure working tree clean (no generated diffs)
        run: git diff --exit-code
      - name: Upload lint artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: lint-${{ github.run_id }}
          path: ${{ env.ARTIFACTS_DIR }}/**
          if-no-files-found: warn

  tests:
    env:
      PIXI_PLATFORM: linux-64
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          persist-credentials: false
      - name: Set artifacts dir
        run: echo "ARTIFACTS_DIR=$RUNNER_TEMP/artifacts-tests" >> "$GITHUB_ENV"
      - name: Prepare artifacts directory
        run: mkdir -p "$ARTIFACTS_DIR"
      - uses: prefix-dev/setup-pixi@82d477f15f3a381dbcc8adc1206ce643fe110fb7 # v0.9.3
        with:
          cache: true
          locked: true
          environments: automation
      - name: Run tests (with coverage)
        env:
          PYTEST_ADDOPTS: "--cov-report=xml:${ARTIFACTS_DIR}/coverage.xml --junitxml=${ARTIFACTS_DIR}/tests.xml"
        run: |
          set -o pipefail
          pixi run -e automation tests | tee "$ARTIFACTS_DIR/tests.log"
      - name: Upload test artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: tests-${{ github.run_id }}
          path: ${{ env.ARTIFACTS_DIR }}/**
          if-no-files-found: warn

  build:
    needs: [lint, tests]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        os: [focal, noble]
        env: [stable]
    permissions:
      contents: read
      packages: write
      id-token: write
      attestations: write
    env:
      PIXI_PLATFORM: linux-64
      REGISTRY: ghcr.io/ray-manaloto/pixi-devcontainer
      BUILD_OS: ${{ matrix.os }}
      BUILD_ENV: ${{ matrix.env }}
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          persist-credentials: false
      - name: Set artifacts dir
        run: echo "ARTIFACTS_DIR=$RUNNER_TEMP/artifacts-${{ matrix.os }}-${{ matrix.env }}" >> "$GITHUB_ENV"
      - name: Prepare artifacts directory
        run: mkdir -p "$ARTIFACTS_DIR" build
      - uses: prefix-dev/setup-pixi@82d477f15f3a381dbcc8adc1206ce643fe110fb7 # v0.9.3
        with:
          cache: true
          locked: true
          environments: automation
      - uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # v3.12.0
        with:
          driver-opts: |
            image=moby/buildkit:latest
            network=host
            env.BUILDKIT_STEP_LOG_MAX_SIZE=10485760
            env.BUILDKIT_STEP_LOG_MAX_SPEED=10485760
      - name: Capture buildx info
        run: docker buildx inspect > "$ARTIFACTS_DIR/buildx-info.txt"
      - name: Login to GHCR
        uses: docker/login-action@5e57cd118135c172c3672efd75eb46360885c0ef # v3.6.0
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_PAT != '' && secrets.GHCR_PAT || secrets.GITHUB_TOKEN }}
      - name: Bake plan
        run: |
          docker buildx bake -f docker/docker-bake.hcl \
            image-${{ matrix.os }}-${{ matrix.env }} \
            artifact-${{ matrix.os }}-${{ matrix.env }} \
            --print > "$ARTIFACTS_DIR/bake-plan.json"
      - name: Build devcontainer images
        id: build
        run: |
          set -o pipefail
          BUILD_TARGETS="image-${BUILD_OS}-${BUILD_ENV} artifact-${BUILD_OS}-${BUILD_ENV}" \
          pixi run -e automation build | tee "$ARTIFACTS_DIR/build.log"
      - name: Export config hash for downstream steps
        if: always()
        env:
          HASH: ${{ steps.build.outputs.HASH || 'unknown' }}
        run: printf 'CONFIG_HASH=%s\n' "$HASH" >> "$GITHUB_ENV"
      - name: Summarize OCI artifacts
        env:
          REGISTRY: ${{ env.REGISTRY }}
        run: |
          python - <<'PY'
          import json
          from pathlib import Path
          import os

          config_hash = os.environ.get("CONFIG_HASH", "unknown")
          registry = os.environ.get("REGISTRY", "ghcr.io/ray-manaloto/pixi-devcontainer")
          os_name = os.environ.get("BUILD_OS", "focal")
          env_name = os.environ.get("BUILD_ENV", "stable")

          artifacts = []
          for tar in Path("build").glob("*.tar"):
              stat = tar.stat()
              artifacts.append(
                  {
                      "file": tar.name,
                      "size_bytes": stat.st_size,
                      "modified": stat.st_mtime,
                  },
              )

          planned = [
              {
                  "image": f"{registry}:{os_name}-{env_name}-{config_hash}",
                  "latest": f"{registry}:{os_name}-{env_name}-latest",
                  "os": os_name,
                  "env": env_name,
              },
          ]

          out_dir = Path(os.environ["ARTIFACTS_DIR"])
          out_dir.mkdir(parents=True, exist_ok=True)
          (out_dir / "oci-metadata.json").write_text(
              json.dumps({"images": artifacts, "planned_tags": planned}, indent=2),
              encoding="utf-8",
          )
          PY
      - name: Capture GHCR upload status
        env:
          REGISTRY: ${{ env.REGISTRY }}
        run: |
          python - <<'PY'
          import datetime as dt
          import json
          import os
          import subprocess
          from pathlib import Path

          registry = os.environ.get("REGISTRY", "ghcr.io/ray-manaloto/pixi-devcontainer")
          config_hash = os.environ.get("CONFIG_HASH", "unknown")
          os_name = os.environ.get("BUILD_OS", "focal")
          env_name = os.environ.get("BUILD_ENV", "stable")
          out_dir = Path(os.environ["ARTIFACTS_DIR"])
          out_dir.mkdir(parents=True, exist_ok=True)

          package_url = "https://github.com/users/ray-manaloto/packages/container/pixi-devcontainer"
          records = []
          for suffix in (config_hash, "latest"):
              tag = f"{registry}:{os_name}-{env_name}-{suffix}"
              entry: dict[str, object] = {
                  "image": tag,
                  "os": os_name,
                  "env": env_name,
                  "tag_suffix": suffix,
                  "config_hash": config_hash,
                  "attestations": ["provenance", "sbom"],
                  "checked_at": dt.datetime.utcnow().isoformat(timespec="seconds") + "Z",
              }
              try:
                  raw = subprocess.check_output(  # noqa: S603
                      ["docker", "buildx", "imagetools", "inspect", "--raw", tag],
                      text=True,
                  )
                  data = json.loads(raw)
                  manifests = data.get("manifests") or []
                  platforms = []
                  sizes = []
                  digest = None
                  for manifest in manifests:
                      platform = manifest.get("platform") or {}
                      if platform:
                          platforms.append(
                              f"{platform.get('os', '?')}/{platform.get('architecture', '?')}",
                          )
                      if manifest.get("size"):
                          sizes.append(manifest["size"])
                      if manifest.get("digest") and not digest:
                          digest = manifest["digest"]
                  entry.update(
                      {
                          "status": "available",
                          "digest": digest or data.get("config", {}).get("digest"),
                          "platforms": platforms,
                          "size_bytes_total": sum(sizes) if sizes else None,
                      },
                  )
              except subprocess.CalledProcessError as exc:  # noqa: PERF203
                  entry.update({"status": "inspect_failed", "error": str(exc)})
              records.append(entry)

          payload = {"images": records}
          (out_dir / "ghcr-status.json").write_text(
              json.dumps(payload, indent=2),
              encoding="utf-8",
          )
          lines = ["| image | status | digest | platforms | size_bytes |", "|---|---|---|---|---|"]
          for rec in records:
              image_link = f"[{rec['image']}]({package_url})"
              lines.append(
                  f"| {image_link} | {rec.get('status')} | {rec.get('digest') or 'n/a'} | "
                  f"{', '.join(rec.get('platforms') or []) or 'n/a'} | "
                  f"{rec.get('size_bytes_total') or 'n/a'} |",
              )
          (out_dir / "ghcr-status.md").write_text("\n".join(lines), encoding="utf-8")
          PY
      - name: Append build summary to job summary
        if: always()
        env:
          REGISTRY: ${{ env.REGISTRY }}
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          summary_path = Path(os.environ["GITHUB_STEP_SUMMARY"])
          artifacts = Path(os.environ["ARTIFACTS_DIR"])
          registry = os.environ.get("REGISTRY", "ghcr.io/ray-manaloto/pixi-devcontainer")
          config_hash = os.environ.get("CONFIG_HASH", "unknown")
          os_name = os.environ.get("BUILD_OS", "focal")
          env_name = os.environ.get("BUILD_ENV", "stable")

          ghcr_status = {}
          try:
              ghcr_status = json.loads((artifacts / "ghcr-status.json").read_text(encoding="utf-8"))
          except FileNotFoundError:
              pass

          lines = [
              "## GHCR Images",
              "| image | status | digest | platforms | size_bytes |",
              "|---|---|---|---|---|",
          ]
          for rec in ghcr_status.get("images", []):
              image_link = f"[{rec['image']}]({registry})"
              lines.append(
                  f"| {image_link} | {rec.get('status')} | {rec.get('digest', 'n/a')} | "
                  f"{', '.join(rec.get('platforms') or []) or 'n/a'} | {rec.get('size_bytes_total') or 'n/a'} |",
              )

          lines.extend(
              [
                  "",
                  f"Config hash: `{config_hash}`",
                  f"Artifacts dir: `{artifacts}`",
                  f"Target: `{os_name}-{env_name}`",
              ],
          )

          with summary_path.open("a", encoding="utf-8") as handle:
              handle.write("\n".join(lines) + "\n")
          PY
      - name: Upload build artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: build-${{ github.run_id }}-${{ matrix.os }}-${{ matrix.env }}
          path: ${{ env.ARTIFACTS_DIR }}/**
          if-no-files-found: warn
